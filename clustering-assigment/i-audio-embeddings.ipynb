{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Feature Extraction and Clustering\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Extract audio features like chromagrams from audio files.\n",
    "2. Cluster audio files based on their feature distributions using K-means.\n",
    "\n",
    "## Prerequisites\n",
    "Install the necessary libraries before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install -y ffmpeg\n",
    "!pip install eyed3\n",
    "!pip install pydub\n",
    "!pip install pyAudioAnalysis\n",
    "!pip install tensorflow pandas matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pyAudioAnalysis import audioBasicIO, audioFeatureExtraction\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions\n",
    "These functions extract chromagrams, compute note frequencies, and visualize features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChromagram(audioData):\n",
    "    \"\"\"Generates a chromagram from the audio features.\"\"\"\n",
    "    temp_data = audioData[21].reshape(1, audioData[21].shape[0])\n",
    "    chromagram = temp_data\n",
    "    for i in range(22, 33):\n",
    "        temp_data = audioData[i].reshape(1, audioData[i].shape[0])\n",
    "        chromagram = np.vstack([chromagram, temp_data])\n",
    "    return chromagram\n",
    "\n",
    "def getNoteFrequency(chromagram):\n",
    "    \"\"\"Computes the note frequency from the chromagram.\"\"\"\n",
    "    numberOfWindows = chromagram.shape[1]\n",
    "    freqVal = chromagram.argmax(axis=0)\n",
    "    histogram, _ = np.histogram(freqVal, bins=12)\n",
    "    normalized_hist = histogram.reshape(1, 12).astype(float) / numberOfWindows\n",
    "    return normalized_hist\n",
    "\n",
    "def plotHeatmap(chromagram, smallSample=True):\n",
    "    \"\"\"Plots a heatmap for the chromagram.\"\"\"\n",
    "    notesLabels = [\"G#\", \"G\", \"F#\", \"F\", \"E\", \"D#\", \"D\", \"C#\", \"C\", \"B\", \"A#\", \"A\"]\n",
    "    fig, axis = plt.subplots()\n",
    "    im = axis.imshow(chromagram[:, 0:25] if smallSample else chromagram, cmap=\"YlGn\")\n",
    "    cbar = axis.figure.colorbar(im, ax=axis, cmap=\"YlGn\")\n",
    "    cbar.ax.set_ylabel(\"Amplitude\", rotation=-90, va=\"bottom\")\n",
    "    axis.set_yticks(np.arange(len(notesLabels)))\n",
    "    axis.set_yticklabels(notesLabels)\n",
    "    axis.set_title(\"Chromagram\")\n",
    "    plt.show()\n",
    "\n",
    "def noteFrequencyPlot(noteFrequency):\n",
    "    \"\"\"Plots the note frequency distribution.\"\"\"\n",
    "    fig, axis = plt.subplots()\n",
    "    axis.plot(np.arange(1, 13), noteFrequency[0, :])\n",
    "    plt.title(\"Note Frequency Distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Audio Data\n",
    "Define a function to preprocess and extract features from an audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(file_path):\n",
    "    \"\"\"Extracts audio features from the given file.\"\"\"\n",
    "    [Fs, x] = audioBasicIO.read_audio_file(file_path)\n",
    "    features, feature_names = audioFeatureExtraction.st_feature_extraction(x, Fs, 0.050 * Fs, 0.025 * Fs)\n",
    "    return feature_names, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Extract Features for a Single Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example File\n",
    "file_path = \"../input/sample_audio.wav\"  # Replace with the actual path\n",
    "\n",
    "# Extract Features\n",
    "feature_name, features = preProcess(file_path)\n",
    "chromagram = getChromagram(features)\n",
    "plotHeatmap(chromagram)\n",
    "\n",
    "# Compute and Plot Note Frequency\n",
    "noteFrequency = getNoteFrequency(chromagram)\n",
    "noteFrequencyPlot(noteFrequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset\n",
    "Iterate over multiple audio files and create a dataset of note frequency arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = []\n",
    "\n",
    "def getDataset(filePath):\n",
    "    \"\"\"Generates a dataset from audio files in a directory.\"\"\"\n",
    "    X = pd.DataFrame()\n",
    "    columns = [\"G#\", \"G\", \"F#\", \"F\", \"E\", \"D#\", \"D\", \"C#\", \"C\", \"B\", \"A#\", \"A\"]\n",
    "    \n",
    "    for root, dirs, filenames in os.walk(filePath):\n",
    "        for file in filenames:\n",
    "            fileList.append(file)\n",
    "            feature_name, features = preProcess(filePath + file)\n",
    "            chromagram = getChromagram(features)\n",
    "            noteFrequency = getNoteFrequency(chromagram)\n",
    "            x_new = pd.Series(noteFrequency[0, :])\n",
    "            X = pd.concat([X, x_new], axis=1)\n",
    "\n",
    "    data = X.T.copy()\n",
    "    data.columns = columns\n",
    "    data.index = [i for i in range(data.shape[0])]\n",
    "    return data\n",
    "\n",
    "dataset_path = \"../input/\"  # Replace with actual directory\n",
    "data = getDataset(dataset_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering on Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "k = 3\n",
    "epochs = 2000\n",
    "\n",
    "# Initialize Variables\n",
    "X = tf.Variable(data.values, name=\"X\")\n",
    "X_labels = tf.Variable(tf.zeros(shape=(X.shape[0],), dtype=tf.int64), name=\"X_labels\")\n",
    "C = tf.Variable(data.values[:k], name=\"C\")\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    X_labels.assign(tf.argmin(tf.reduce_sum(tf.square(tf.expand_dims(X, 0) - tf.expand_dims(C, 1)), axis=2), axis=0))\n",
    "    sums = tf.math.unsorted_segment_sum(X, X_labels, k)\n",
    "    counts = tf.math.unsorted_segment_sum(tf.ones_like(X), X_labels, k)\n",
    "    C.assign(sums / counts)\n",
    "\n",
    "# Assign Final Labels\n",
    "final_labels = pd.DataFrame({\"Labels\": X_labels.numpy(), \"File Names\": fileList})\n",
    "print(final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=final_labels[\"Labels\"], cmap=\"viridis\")\n",
    "plt.title(\"Clustering Results\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
